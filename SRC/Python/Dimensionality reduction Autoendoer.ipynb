{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Dimensionality reduction Autoencoder"
      ],
      "metadata": {
        "id": "8HUZPnuE7Cao"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pW8ryXgGEWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adfa07fe-9979-4996-c55f-30bfd2f5ed7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading data \n",
            "\n",
            "Model: \"model_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 661)]             0         \n",
            "                                                                 \n",
            " encoder_layer_1 (Dense)     (None, 500)               331000    \n",
            "                                                                 \n",
            " encoder_layer_2 (Dense)     (None, 100)               50100     \n",
            "                                                                 \n",
            " bottleneck_layer (Dense)    (None, 25)                2525      \n",
            "                                                                 \n",
            " decoder_layer_2 (Dense)     (None, 100)               2600      \n",
            "                                                                 \n",
            " decoder_layer_1 (Dense)     (None, 500)               50500     \n",
            "                                                                 \n",
            " op_layer (Dense)            (None, 661)               331161    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 767886 (2.93 MB)\n",
            "Trainable params: 767886 (2.93 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.1111 \n",
            "Epoch 1: val_loss improved from inf to 0.11049, saving model to AE_reduced_dataset_1_01_0.11.hdf5\n",
            "12/12 [==============================] - 2s 32ms/step - loss: 0.1108 - val_loss: 0.1105\n",
            "Epoch 2/200\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0951\n",
            "Epoch 2: val_loss improved from 0.11049 to 0.10247, saving model to AE_reduced_dataset_1_02_0.10.hdf5\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0949 - val_loss: 0.1025\n",
            "Epoch 3/200\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0906\n",
            "Epoch 3: val_loss improved from 0.10247 to 0.10109, saving model to AE_reduced_dataset_1_03_0.10.hdf5\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0905 - val_loss: 0.1011\n",
            "Epoch 4/200\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0898\n",
            "Epoch 4: val_loss improved from 0.10109 to 0.10082, saving model to AE_reduced_dataset_1_04_0.10.hdf5\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0897 - val_loss: 0.1008\n",
            "Epoch 5/200\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.0893\n",
            "Epoch 5: val_loss did not improve from 0.10082\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0893 - val_loss: 0.1010\n",
            "Epoch 6/200\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0892\n",
            "Epoch 6: val_loss did not improve from 0.10082\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0891 - val_loss: 0.1008\n",
            "Epoch 7/200\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0888\n",
            "Epoch 7: val_loss improved from 0.10082 to 0.10047, saving model to AE_reduced_dataset_1_07_0.10.hdf5\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0889 - val_loss: 0.1005\n",
            "Epoch 8/200\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0890\n",
            "Epoch 8: val_loss improved from 0.10047 to 0.10031, saving model to AE_reduced_dataset_1_08_0.10.hdf5\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0887 - val_loss: 0.1003\n",
            "Epoch 9/200\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0895\n",
            "Epoch 9: val_loss improved from 0.10031 to 0.10003, saving model to AE_reduced_dataset_1_09_0.10.hdf5\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0885 - val_loss: 0.1000\n",
            "Epoch 10/200\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0881\n",
            "Epoch 10: val_loss improved from 0.10003 to 0.09780, saving model to AE_reduced_dataset_1_10_0.10.hdf5\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0879 - val_loss: 0.0978\n",
            "Epoch 11/200\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0860\n",
            "Epoch 11: val_loss improved from 0.09780 to 0.09625, saving model to AE_reduced_dataset_1_11_0.10.hdf5\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0861 - val_loss: 0.0962\n",
            "Epoch 12/200\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0835\n",
            "Epoch 12: val_loss improved from 0.09625 to 0.09575, saving model to AE_reduced_dataset_1_12_0.10.hdf5\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0847 - val_loss: 0.0958\n",
            "Epoch 13/200\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0843\n",
            "Epoch 13: val_loss did not improve from 0.09575\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0843 - val_loss: 0.0958\n",
            "Epoch 14/200\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 0.0828\n",
            "Epoch 14: val_loss improved from 0.09575 to 0.09527, saving model to AE_reduced_dataset_1_14_0.10.hdf5\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0840 - val_loss: 0.0953\n",
            "Epoch 15/200\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0832\n",
            "Epoch 15: val_loss did not improve from 0.09527\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0839 - val_loss: 0.0954\n",
            "Epoch 16/200\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0831\n",
            "Epoch 16: val_loss improved from 0.09527 to 0.09505, saving model to AE_reduced_dataset_1_16_0.10.hdf5\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0835 - val_loss: 0.0950\n",
            "Epoch 17/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0841\n",
            "Epoch 17: val_loss improved from 0.09505 to 0.09499, saving model to AE_reduced_dataset_1_17_0.09.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0832 - val_loss: 0.0950\n",
            "Epoch 18/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0849\n",
            "Epoch 18: val_loss improved from 0.09499 to 0.09498, saving model to AE_reduced_dataset_1_18_0.09.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0831 - val_loss: 0.0950\n",
            "Epoch 19/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0758\n",
            "Epoch 19: val_loss improved from 0.09498 to 0.09493, saving model to AE_reduced_dataset_1_19_0.09.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0828 - val_loss: 0.0949\n",
            "Epoch 20/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0867\n",
            "Epoch 20: val_loss improved from 0.09493 to 0.09456, saving model to AE_reduced_dataset_1_20_0.09.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0825 - val_loss: 0.0946\n",
            "Epoch 21/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0692\n",
            "Epoch 21: val_loss improved from 0.09456 to 0.09180, saving model to AE_reduced_dataset_1_21_0.09.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0813 - val_loss: 0.0918\n",
            "Epoch 22/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0770\n",
            "Epoch 22: val_loss improved from 0.09180 to 0.09127, saving model to AE_reduced_dataset_1_22_0.09.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0784 - val_loss: 0.0913\n",
            "Epoch 23/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0755\n",
            "Epoch 23: val_loss improved from 0.09127 to 0.09017, saving model to AE_reduced_dataset_1_23_0.09.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0775 - val_loss: 0.0902\n",
            "Epoch 24/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0748\n",
            "Epoch 24: val_loss improved from 0.09017 to 0.08964, saving model to AE_reduced_dataset_1_24_0.09.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0767 - val_loss: 0.0896\n",
            "Epoch 25/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0782\n",
            "Epoch 25: val_loss improved from 0.08964 to 0.08943, saving model to AE_reduced_dataset_1_25_0.09.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0762 - val_loss: 0.0894\n",
            "Epoch 26/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0657\n",
            "Epoch 26: val_loss improved from 0.08943 to 0.08895, saving model to AE_reduced_dataset_1_26_0.09.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0757 - val_loss: 0.0889\n",
            "Epoch 27/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0821\n",
            "Epoch 27: val_loss improved from 0.08895 to 0.08890, saving model to AE_reduced_dataset_1_27_0.09.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0752 - val_loss: 0.0889\n",
            "Epoch 28/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0824\n",
            "Epoch 28: val_loss improved from 0.08890 to 0.08888, saving model to AE_reduced_dataset_1_28_0.09.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0749 - val_loss: 0.0889\n",
            "Epoch 29/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0720\n",
            "Epoch 29: val_loss improved from 0.08888 to 0.08849, saving model to AE_reduced_dataset_1_29_0.09.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0745 - val_loss: 0.0885\n",
            "Epoch 30/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0841\n",
            "Epoch 30: val_loss improved from 0.08849 to 0.08849, saving model to AE_reduced_dataset_1_30_0.09.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0742 - val_loss: 0.0885\n",
            "Epoch 31/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0693\n",
            "Epoch 31: val_loss improved from 0.08849 to 0.08839, saving model to AE_reduced_dataset_1_31_0.09.hdf5\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0739 - val_loss: 0.0884\n",
            "Epoch 32/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0785\n",
            "Epoch 32: val_loss improved from 0.08839 to 0.08829, saving model to AE_reduced_dataset_1_32_0.09.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0737 - val_loss: 0.0883\n",
            "Epoch 33/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0844\n",
            "Epoch 33: val_loss improved from 0.08829 to 0.08805, saving model to AE_reduced_dataset_1_33_0.09.hdf5\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0734 - val_loss: 0.0881\n",
            "Epoch 34/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0704\n",
            "Epoch 34: val_loss did not improve from 0.08805\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0732 - val_loss: 0.0882\n",
            "Epoch 35/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0625\n",
            "Epoch 35: val_loss improved from 0.08805 to 0.08791, saving model to AE_reduced_dataset_1_35_0.09.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0730 - val_loss: 0.0879\n",
            "Epoch 36/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0664\n",
            "Epoch 36: val_loss did not improve from 0.08791\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0729 - val_loss: 0.0881\n",
            "Epoch 37/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0822\n",
            "Epoch 37: val_loss improved from 0.08791 to 0.08783, saving model to AE_reduced_dataset_1_37_0.09.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0728 - val_loss: 0.0878\n",
            "Epoch 38/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0645\n",
            "Epoch 38: val_loss improved from 0.08783 to 0.08723, saving model to AE_reduced_dataset_1_38_0.09.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0724 - val_loss: 0.0872\n",
            "Epoch 39/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0694\n",
            "Epoch 39: val_loss improved from 0.08723 to 0.08691, saving model to AE_reduced_dataset_1_39_0.09.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0719 - val_loss: 0.0869\n",
            "Epoch 40/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0672\n",
            "Epoch 40: val_loss did not improve from 0.08691\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0716 - val_loss: 0.0870\n",
            "Epoch 41/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0701\n",
            "Epoch 41: val_loss improved from 0.08691 to 0.08687, saving model to AE_reduced_dataset_1_41_0.09.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0712 - val_loss: 0.0869\n",
            "Epoch 42/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0677\n",
            "Epoch 42: val_loss improved from 0.08687 to 0.08666, saving model to AE_reduced_dataset_1_42_0.09.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0707 - val_loss: 0.0867\n",
            "Epoch 43/200\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0708\n",
            "Epoch 43: val_loss did not improve from 0.08666\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0706 - val_loss: 0.0870\n",
            "Epoch 44/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0829\n",
            "Epoch 44: val_loss did not improve from 0.08666\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0705 - val_loss: 0.0869\n",
            "Epoch 45/200\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.0703\n",
            "Epoch 45: val_loss improved from 0.08666 to 0.08648, saving model to AE_reduced_dataset_1_45_0.09.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0703 - val_loss: 0.0865\n",
            "Epoch 46/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0660\n",
            "Epoch 46: val_loss improved from 0.08648 to 0.08630, saving model to AE_reduced_dataset_1_46_0.09.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0698 - val_loss: 0.0863\n",
            "Epoch 47/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0639\n",
            "Epoch 47: val_loss did not improve from 0.08630\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0697 - val_loss: 0.0868\n",
            "Epoch 48/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0741\n",
            "Epoch 48: val_loss did not improve from 0.08630\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0697 - val_loss: 0.0867\n",
            "Epoch 49/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0579\n",
            "Epoch 49: val_loss did not improve from 0.08630\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0694 - val_loss: 0.0866\n",
            "Epoch 50/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0711\n",
            "Epoch 50: val_loss did not improve from 0.08630\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0693 - val_loss: 0.0864\n",
            "Epoch 51/200\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.0766\n",
            "Epoch 51: val_loss did not improve from 0.08630\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0691 - val_loss: 0.0866\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "(296, 25)\n",
            "                    0         1         2    3         4\n",
            "TCGA.04.1341.01A  0.0  2.042951  1.155561  0.0  2.841098\n",
            "TCGA.04.1343.01A  0.0  2.616323  1.282128  0.0  3.451238\n",
            "TCGA.04.1348.01A  0.0  1.772576  0.850534  0.0  0.691640\n",
            "TCGA.04.1356.01A  0.0  0.671939  1.289824  0.0  1.837709\n",
            "TCGA.04.1357.01A  0.0  1.697938  1.559303  0.0  1.765665\n",
            "Training Loss:  0.06910043954849243\n",
            "Validation Loss:  0.08657154440879822\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "# Load required libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "import tensorflow.keras.optimizers as optimizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "#%%\n",
        "# Declaring file names\n",
        "# Path to input file\n",
        "ip_training_file = \"mirna_prot.csv\"\n",
        "# Path to output file\n",
        "op_file = \"AE_reduced_mirna_prot.csv\"\n",
        "# Save checkpoints while training\n",
        "checkpoint_filepath = \"AE_reduced_dataset_1_{epoch:02d}_{val_loss:.2f}.hdf5\"\n",
        "# Path to save AE loss image\n",
        "fig_path =  \"AE_reduced_dataset_1_loss.png\"\n",
        "\n",
        "#%%\n",
        "# Data preprocessing\n",
        "print(\"Reading data \\n\")\n",
        "training_data = pd.read_csv(ip_training_file, index_col=0)\n",
        "training_data.shape\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, train_ground,valid_ground = train_test_split(training_data, training_data, test_size = 0.1, shuffle = True, random_state = 122131)\n",
        "X_train.shape\n",
        "X_test.shape\n",
        "\n",
        "#%%\n",
        "# Function to save weights when there is reduction in validation loss\n",
        "model_checkpoint_callback = ModelCheckpoint(filepath = checkpoint_filepath, save_weights_only = True, verbose = 1, monitor = 'val_loss', mode = 'min', save_best_only = True)\n",
        "\n",
        "# Early stopping function i.e stop training the model if the validation loss remains same for five subsequent epochs\n",
        "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 5)\n",
        "\n",
        "# Declare number of layers and nodes in each layer of AE\n",
        "# Size of input data i.e dimension of input data, required to declare number of nodes in first and last layer of AE\n",
        "ip_dim_size = X_train.shape[1]\n",
        "# Size of encoded representations\n",
        "encoding_dim_1 = 500\n",
        "encoding_dim_2 = 100\n",
        "encoding_dim_3 = 25\n",
        "\n",
        "\n",
        "\n",
        "# Declare structure of AE\n",
        "# Encoder section\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "ip_dim_shape = Input(shape = (ip_dim_size,), name=\"input_layer\")\n",
        "x = Dense(encoding_dim_1, activation='relu', kernel_initializer = 'uniform', name = 'encoder_layer_1')(ip_dim_shape)\n",
        "x = Dense(encoding_dim_2, activation='relu', kernel_initializer = 'uniform', name = 'encoder_layer_2')(x)\n",
        "#x = Dense(encoding_dim_3, activation='relu', kernel_initializer = 'uniform', name = 'encoder_layer_3')(x)\n",
        "#x = Dense(encoding_dim_4, activation='relu', kernel_initializer = 'uniform', name = 'encoder_layer_4')(x)\n",
        "encoded = Dense(encoding_dim_2, activation='relu', kernel_initializer = 'uniform', name=\"bottleneck_layer\")(x)\n",
        "\n",
        "# Decoder section\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "#y = Dense(encoding_dim_4, activation='relu', kernel_initializer = 'uniform', name=\"decoder_layer_4\")(encoded)\n",
        "#y = Dense(encoding_dim_3, activation='relu', kernel_initializer = 'uniform', name=\"decoder_layer_3\")(encoded)\n",
        "y = Dense(encoding_dim_2, activation='relu', kernel_initializer = 'uniform', name=\"decoder_layer_2\")(encoded)\n",
        "y = Dense(encoding_dim_1, activation='relu', kernel_initializer = 'uniform', name=\"decoder_layer_1\")(y)\n",
        "decoded = Dense(ip_dim_size, activation='relu', kernel_initializer = 'uniform', name=\"op_layer\")(y)\n",
        "\n",
        "# This model maps an input to its reconstruction\n",
        "autoencoder = Model(inputs = ip_dim_shape, outputs = decoded)\n",
        "autoencoder.summary()\n",
        "\n",
        "# Hyper-paramters to train the model\n",
        "learning_rate = 0.001 # Vary or put in loop\n",
        "batch_size = 24 # Vary depending on the memory of GPU\n",
        "epochs = 200\n",
        "# Initialize required optimizer with learning rate\n",
        "opt_adam = optimizer.Adam(learning_rate = learning_rate)\n",
        "# Compile the model\n",
        "autoencoder.compile(optimizer = opt_adam, loss = 'mean_squared_error')\n",
        "\n",
        "# Train/fit the model\n",
        "estimator = autoencoder.fit(X_train, X_train, # input and output data\n",
        "                epochs = epochs,\n",
        "                batch_size = batch_size,\n",
        "                shuffle = True,\n",
        "                validation_data = (X_test, X_test), # Validation data\n",
        "                callbacks = [early_stopping_callback, model_checkpoint_callback])\n",
        "\n",
        "#%%\n",
        "# Get reduced dimensional representation\n",
        "# Get the encoder section of AE model\n",
        "encoder = Model(inputs = ip_dim_shape, outputs = encoded)\n",
        "# Get reduced dimension data for input data\n",
        "bottleneck_representation = encoder.predict(training_data)\n",
        "bottleneck_representation.shape\n",
        "# Convert result to dataframe - required to write to csv file\n",
        "bottleneck_representation_df = pd.DataFrame(data = bottleneck_representation, index = training_data.index)\n",
        "print(bottleneck_representation_df.shape)\n",
        "print(bottleneck_representation_df.iloc[0:5, 0:5])\n",
        "# Write result to csv file\n",
        "bottleneck_representation_df.to_csv(op_file, index = True)\n",
        "\n",
        "#%%\n",
        "# Obtain loss plot\n",
        "print(\"Training Loss: \", estimator.history['loss'][-1])\n",
        "print(\"Validation Loss: \", estimator.history['val_loss'][-1])\n",
        "plt.plot(estimator.history['loss'])\n",
        "plt.plot(estimator.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'], loc = 'upper right')\n",
        "plt.savefig(fig_path)\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is repeated for each single omic separately, and for each combination. The following figure shows each combination with its AE architecture (mRNA is represented by L1, miRNA by L2, methylation by L3, and proteome by L4).\n",
        "\n",
        "\n",
        "![Capture.PNG](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IV60tuWa7kWV"
      }
    }
  ]
}