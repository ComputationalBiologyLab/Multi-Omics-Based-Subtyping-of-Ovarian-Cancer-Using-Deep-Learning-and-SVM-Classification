{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qC7jhRQ9QXZd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import (accuracy_score, precision_score, f1_score,\n",
        "                             recall_score, confusion_matrix, roc_curve, auc)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Function to select features from a single CSV file using ExtraTreesClassifier\n",
        "def select_features(data_file, y):\n",
        "    X = pd.read_csv(data_file, index_col=0)\n",
        "    etc = ExtraTreesClassifier(n_estimators=100)\n",
        "    etc.fit(X, y)\n",
        "    selector = SelectFromModel(etc, max_features=90, prefit=True)\n",
        "    selected_features = X.columns[selector.get_support()]\n",
        "    return X[selected_features]\n",
        "\n",
        "# Function to run SVM with feature selection and hyperparameter tuning on the combined features\n",
        "def run_svm_with_combined_features(data_files, label_file):\n",
        "    # Read the label file\n",
        "    y = pd.read_csv(label_file, index_col=0).values.ravel()\n",
        "\n",
        "    # Convert labels from {1, 2} to {0, 1}\n",
        "    y = np.where(y == 2, 1, 0)\n",
        "\n",
        "    # Select features for each data file\n",
        "    selected_dataframes = [select_features(data_file, y) for data_file in data_files]\n",
        "\n",
        "    # Combine the selected features\n",
        "    X_combined = pd.concat(selected_dataframes, axis=1)\n",
        "\n",
        "    # Standardize the combined features\n",
        "    scaler = StandardScaler()\n",
        "    X_combined = scaler.fit_transform(X_combined)\n",
        "\n",
        "    # Create the SVM classifier\n",
        "    svm = SVC(kernel='rbf', probability=True)\n",
        "\n",
        "    # Define the hyperparameter grid\n",
        "    param_grid = {\n",
        "        'C': [0.1, 1, 10, 100],\n",
        "        'gamma': [1, 0.1, 0.01, 0.001]\n",
        "    }\n",
        "\n",
        "    # Create the cross-validation procedure\n",
        "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
        "\n",
        "    # Create GridSearchCV\n",
        "    grid_search = GridSearchCV(svm, param_grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "    # Fit GridSearchCV\n",
        "    grid_search.fit(X_combined, y)\n",
        "\n",
        "    # Get the best parameters\n",
        "    best_params = grid_search.best_params_\n",
        "\n",
        "    # Initialize lists to store the metrics\n",
        "    accuracies = []\n",
        "    precisions = []\n",
        "    f1_scores = []\n",
        "    sensitivities = []\n",
        "    specificities = []\n",
        "    aucs = []\n",
        "    tprs = []\n",
        "    fprs = []\n",
        "\n",
        "    # Evaluate the model with the best parameters on cross-validation splits\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    # Loop through the cross-validation splits\n",
        "    for train_index, test_index in cv.split(X_combined, y):\n",
        "        X_train, X_test = X_combined[train_index], X_combined[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # Fit the model and make predictions\n",
        "        best_model.fit(X_train, y_train)\n",
        "        y_pred = best_model.predict(X_test)\n",
        "        y_prob = best_model.predict_proba(X_test)[:, 1]  # Probabilities for ROC\n",
        "\n",
        "        # Calculate the metrics for the current split\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        sensitivity = recall_score(y_test, y_pred)  # Recall is calculated here\n",
        "\n",
        "        # Calculate specificity\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        tn = cm[0, 0]  # True Negatives\n",
        "        fp = cm[0, 1]  # False Positives\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "        # Calculate ROC AUC\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        # Store metrics\n",
        "        accuracies.append(accuracy)\n",
        "        precisions.append(precision)\n",
        "        f1_scores.append(f1)\n",
        "        sensitivities.append(sensitivity)\n",
        "        specificities.append(specificity)\n",
        "        aucs.append(roc_auc)\n",
        "\n",
        "        # Store TPR and FPR\n",
        "        tprs.append(tpr)\n",
        "        fprs.append(fpr)\n",
        "\n",
        "    # Calculate the mean and standard deviation of the metrics\n",
        "    mean_accuracy = np.mean(accuracies)\n",
        "    mean_precision = np.mean(precisions)\n",
        "    mean_f1 = np.mean(f1_scores)\n",
        "    mean_sensitivity = np.mean(sensitivities)  # Mean Recall\n",
        "    mean_specificity = np.mean(specificities)\n",
        "    mean_auc = np.mean(aucs)\n",
        "\n",
        "    std_accuracy = np.std(accuracies)\n",
        "    std_precision = np.std(precisions)\n",
        "    std_f1 = np.std(f1_scores)\n",
        "    std_sensitivity = np.std(sensitivities)  # Standard Deviation of Recall\n",
        "    std_specificity = np.std(specificities)\n",
        "    std_auc = np.std(aucs)\n",
        "\n",
        "    # Print the selected features for each data file\n",
        "    for i, data_file in enumerate(data_files):\n",
        "        selected_features = selected_dataframes[i].columns\n",
        "        print(f\"Selected features from {data_file}: {', '.join(selected_features)}\")\n",
        "\n",
        "    return (mean_accuracy, std_accuracy, mean_precision, std_precision,\n",
        "            mean_f1, std_f1, mean_sensitivity, std_sensitivity,\n",
        "            mean_specificity, std_specificity, mean_auc, std_auc, best_params,\n",
        "            tprs, fprs)\n",
        "\n",
        "# List of data and label files\n",
        "data_files = [\"mRNA296.csv\", \"mirna296.csv\", \"meth296.csv\"]\n",
        "label_file = \"Labels.csv\"\n",
        "\n",
        "# Run SVM with combined features and print results\n",
        "results = run_svm_with_combined_features(data_files, label_file)\n",
        "print(f\"Mean Accuracy: {results[0]:.2f} ± {results[1]:.2f}\")\n",
        "print(f\"Mean Precision: {results[2]:.2f} ± {results[3]:.2f}\")\n",
        "print(f\"Mean F1-Score: {results[4]:.2f} ± {results[5]:.2f}\")\n",
        "print(f\"Mean Sensitivity (Recall): {results[6]:.2f} ± {results[7]:.2f}\")\n",
        "print(f\"Mean Specificity: {results[8]:.2f} ± {results[9]:.2f}\")\n",
        "print(f\"Mean AUC: {results[10]:.2f} ± {results[11]:.2f}\")\n",
        "print(f\"Best Parameters: {results[12]}\")\n",
        "\n",
        "# Calculate the mean TPR and FPR across all folds\n",
        "mean_tpr = np.mean([np.mean(tpr) for tpr in results[13]])\n",
        "mean_fpr = np.mean([np.mean(fpr) for fpr in results[14]])\n",
        "\n",
        "# Print the mean TPR and FPR\n",
        "print(f\"Mean TPR: {mean_tpr:.2f}\")\n",
        "print(f\"Mean FPR: {mean_fpr:.2f}\")"
      ]
    }
  ]
}